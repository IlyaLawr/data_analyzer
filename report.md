1. Подход который я использовал описан в README.md, последний пункт. Если коротко то мы пишем системую инструкцию для LLM модели, согласно которой она превосходный аналитик со знанием pandas и требуем от нее сгенерировать код в дальнейшем. Потом мы формирует схему наших данных из csv файла и так же передаем в модель. Далее, используя удаленную модель LLM, просим ИИ сгенерировать код который вытянет нужные нам данные используя Python код, отталкиваясь от вопроса пользователя. Выполняем код, получаем результат, формируем через LLM человекочитаемый ответ.

2. Что касается эффективности и точности то мой прототип системы эффективен, так как имеется гибкость как в плане обработки данных разной предметной области так и низкая связность компонентов позволяет без особых усилий заменить один компонент системы на другой. Система работает быстро, дает осмысленный итоговый результат. Что касается точности данных, то к сожалению, в рамках того времени что удалось выделить на тестовое, не удалось протестировать систему как автоматически так и в ручную...

3. Из основных это библиотека "pandas" для обработки csv файлов, библиотека "RestrictedPython" для безопастного исполнения кода, библиотека "httpx" для возможности взаймодействовать с LLM по API, "pydantic" для чтения переменных окружения, так же старался использовать "Onion" архитектуру при написании кода. Все что использовал сработало.

4. Текущую реализацию оценю так:
    - Из плюсов: гибкость системы в целом(как в замене предметной области так и в замене компонентов), скорость работы системы, интерпритируемость ответов.
    - Из минусов(очень мало времени было на реализацию): нет обработок ошибок, нет "retry" логики, нет автотестов, зависимость от удаленного сервиса, нет потокового чтения исходных данных(система может упасть есть будет большой csv файл)

На реализацию потратил около 6-7 часов(деадлайн уже был нарушен), при поступлений тестового физически не мог начать работу, далее 3 дня подряд работал с 8 до 8 часов, многое не удалось реализовать в текущем решений...
